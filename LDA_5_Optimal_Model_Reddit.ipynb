{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 0.012611,
     "end_time": "2019-05-17T16:13:51.891542",
     "exception": false,
     "start_time": "2019-05-17T16:13:51.878931",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_cores = 27\n",
    "mem = 650000\n",
    "config = \"configs.config_Reddit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:30:13.934440Z",
     "start_time": "2019-05-16T07:30:13.930829Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 0.010297,
     "end_time": "2019-05-17T16:13:51.908605",
     "exception": false,
     "start_time": "2019-05-17T16:13:51.898308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "if 'config' not in locals():\n",
    "    config = 'configs.config_SE_test_local'\n",
    "#     config = 'configs.config_Reddit_test_local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:30:19.308846Z",
     "start_time": "2019-05-16T07:30:13.948930Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 11.493872,
     "end_time": "2019-05-17T16:14:03.407971",
     "exception": false,
     "start_time": "2019-05-17T16:13:51.914099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file is set to configs.config_Reddit\n",
      "num_cores is set to 27\n",
      "mem is set to 650000\n"
     ]
    }
   ],
   "source": [
    "### initialization ###\n",
    "\n",
    "from _imports import *\n",
    "# from _utils import *\n",
    "\n",
    "print('config file is set to {}'.format(config))\n",
    "\n",
    "util=importlib.import_module('_utils')\n",
    "importlib.reload(util)\n",
    "\n",
    "c=importlib.import_module(config)\n",
    "importlib.reload(c)\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# param_setup(sys.argv[1:], c)\n",
    "util.param_setup_ipython(globals(), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:30:22.651553Z",
     "start_time": "2019-05-16T07:30:19.311574Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 70.313721,
     "end_time": "2019-05-17T16:15:13.728135",
     "exception": false,
     "start_time": "2019-05-17T16:14:03.414414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225657, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>all_text</th>\n",
       "      <th>group</th>\n",
       "      <th>txt_orig</th>\n",
       "      <th>txt_lemmatized</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2qzibe</td>\n",
       "      <td>2015-01-01 00:29:40</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Measuring human performance on standard image ...</td>\n",
       "      <td>submissions</td>\n",
       "      <td>Measuring human performance on standard image ...</td>\n",
       "      <td>measur, human, zzzltwolfivelonelzzz, standard,...</td>\n",
       "      <td>measur, human, perform, standard, imag classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2qzv35</td>\n",
       "      <td>2015-01-01 03:52:22</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "      <td>European economy guide: Taking Europe’s pulse</td>\n",
       "      <td>submissions</td>\n",
       "      <td>European economy guide: Taking Europe’s pulse</td>\n",
       "      <td>european, economi, guid, take, europ, pul</td>\n",
       "      <td>european, economi, guid, take, europ, pul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2qzzaa</td>\n",
       "      <td>2015-01-01 05:23:25</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "      <td>Popularity of visual forms in DataIsBeautiful ...</td>\n",
       "      <td>submissions</td>\n",
       "      <td>Popularity of visual forms in DataIsBeautiful ...</td>\n",
       "      <td>popular, zzzlthreelzerolfourlzzz, form, datais...</td>\n",
       "      <td>popular, visual, form, dataisbeauti, base, sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2r048c</td>\n",
       "      <td>2015-01-01 07:16:15</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "      <td>JOE GROOMING - DAILY SHAMPOO ~ best shampoo fo...</td>\n",
       "      <td>submissions</td>\n",
       "      <td>JOE GROOMING - DAILY SHAMPOO ~ best shampoo fo...</td>\n",
       "      <td>joe, groom, daili, shampoo, good, shampoo, oil...</td>\n",
       "      <td>joe, groom, daili, shampoo, good, shampoo, oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2r0e7b</td>\n",
       "      <td>2015-01-01 10:25:46</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "      <td>Los Angeles Traffic Accident Rate in Rainy vs ...</td>\n",
       "      <td>submissions</td>\n",
       "      <td>Los Angeles Traffic Accident Rate in Rainy vs ...</td>\n",
       "      <td>trafficaccid, rate, raini, dri, weather</td>\n",
       "      <td>trafficaccid, rate, raini, dri, weather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 27 partitions with 27 cores for para_lemmatize_df\n"
     ]
    }
   ],
   "source": [
    "### cleaned & tagged text loading + tag file loading ###\n",
    "\n",
    "df_text_orig = pd.read_csv('{}{}_1_text_original.csv'.format(c.directory['save'], c.project_name))\n",
    "df_text = pd.read_csv('{}{}_4_text_lemmatized_decoded.csv'.format(c.directory['save'], c.project_name))\n",
    "pprint(df_text.shape)\n",
    "util.display_df(df_text.head())\n",
    "\n",
    "def para_lemmatize(text):\n",
    "    return [x.strip() for x in text.split(',')]\n",
    "\n",
    "def para_lemmatize_df(df):\n",
    "    return df.apply(para_lemmatize)\n",
    "\n",
    "# c.init_parallel(True)\n",
    "# df_text['txt_lemmatized']=df_text['txt_lemmatized'].parallel_apply( para_lemmatize)\n",
    "data_lemmatized = util.parallelize_df(df_text['txt_lemmatized'], para_lemmatize_df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:30:27.816922Z",
     "start_time": "2019-05-16T07:30:22.656263Z"
    },
    "code_folding": [
     0,
     6,
     9
    ],
    "papermill": {
     "duration": 101.650663,
     "end_time": "2019-05-17T16:16:55.386673",
     "exception": false,
     "start_time": "2019-05-17T16:15:13.736010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 27 partitions with 27 cores for para_corpus_df\n"
     ]
    }
   ],
   "source": [
    "### preping LDA model ###\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus & Term Document Frequency\n",
    "def para_corpus(text):\n",
    "    return id2word.doc2bow(text)\n",
    "\n",
    "def para_corpus_df(df):\n",
    "    return df.apply(para_corpus)\n",
    "\n",
    "corpus=util.parallelize_df(data_lemmatized, para_corpus_df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:31:03.130442Z",
     "start_time": "2019-05-16T07:30:27.821791Z"
    },
    "code_folding": [
     0,
     2
    ],
    "papermill": {
     "duration": 2246.06048,
     "end_time": "2019-05-17T16:54:21.455208",
     "exception": false,
     "start_time": "2019-05-17T16:16:55.394728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'number of topics = 62, cores = 27, iteration=1000'\n"
     ]
    }
   ],
   "source": [
    "### training the optimal LDA model + saving ###\n",
    "\n",
    "pprint('number of topics = {}, cores = {}, iteration={}'.format(c.num_topics, \n",
    "                                                                  c.num_cores, \n",
    "                                                                  c.optimal_LDA_iteration_threshold\n",
    "                                                                 ))\n",
    "\n",
    "optimal_model = gensim.models.wrappers.LdaMallet(c.directory['mallet'],\n",
    "                                         corpus=corpus, \n",
    "                                         num_topics=c.num_topics, \n",
    "                                         id2word=id2word,\n",
    "                                         workers=c.num_cores,\n",
    "                                         optimize_interval=1,\n",
    "                                         iterations=c.optimal_LDA_iteration_threshold,\n",
    "                                         random_seed=1000\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:31:47.819729Z",
     "start_time": "2019-05-16T07:31:03.134160Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 1092.76694,
     "end_time": "2019-05-17T17:12:34.233599",
     "exception": false,
     "start_time": "2019-05-17T16:54:21.466659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### saving optimal model + corpus  ###\n",
    " \n",
    "try:\n",
    "    os.remove('{}optimal_model-{}-{}.db'.format(c.directory['save'],\n",
    "                                                  c.optimal_LDA_iteration_threshold,\n",
    "                                                  c.num_topics\n",
    "                                                  ))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dbfile = open('{}{}_db_optimal_model-{}-{}.pickle'.format(c.directory['save'],\n",
    "                                                          c.project_name,\n",
    "                                                          c.optimal_LDA_iteration_threshold,\n",
    "                                                          c.num_topics\n",
    "                                                         ), 'ab')\n",
    "db=dict(\n",
    "    model=optimal_model,\n",
    "    num_topics=c.num_topics,\n",
    "    df_text=df_text,\n",
    "    optimal_model_corpus=optimal_model[corpus]\n",
    ")\n",
    "\n",
    "# optimal_model.save('{}{}_db_mallet_model-{}-{}.pickle'.format(c.directory['save'],\n",
    "#                                                               c.project_name,\n",
    "#                                                               c.optimal_LDA_iteration_threshold,\n",
    "#                                                               c.num_topics\n",
    "#                                                              ))\n",
    "pickle.dump(db, dbfile)\n",
    "dbfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 3532.85078,
   "end_time": "2019-05-17T17:12:41.805542",
   "environment_variables": {},
   "exception": null,
   "input_path": "LDA_5_Optimal_Model.ipynb",
   "output_path": "/scratch/hkarbasi/LDA/Reddit/LDA_5_Optimal_Model_0_Reddit_NODE076.ipynb",
   "parameters": {
    "config": "configs.config_Reddit",
    "mem": 650000,
    "num_cores": 27
   },
   "start_time": "2019-05-17T16:13:48.954762",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
